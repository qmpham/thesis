\chapter{Introduction}
For a long time, Machine Translation(MT\nomenclature[mt]{MT}{Machine Translation}) has evolved around data-driven methods including Statistical Machine Translation (SMT\nomenclature[smt]{SMT}{Statistical Machine Translation}) and Neural Machine Translation (NMT\nomenclature[nmt]{NMT}{Neural Machine Translation}). Learning from data is the cheapest and the most computationally efficient road to building such intelligent systems for the Machine Translation task. SMT had achieved many success in the translation industry before the NMT era. Then, for nearly a half decade, NMT models have surpassed SMT models in the high-resource language pairs such as French(Fr\nomenclature[fr]{Fr}{French}) - English(En\nomenclature[en]{En}{English}), German(De\nomenclature[de]{De}{German}) - English thanks to their extremely complex architecture. With data-driven methods as SMT and NMT, it becomes a unique paradigm that the more training data is fed, the better the model performs. However, SMT and NMT models perform badly with text that came from a different context than training data. NMT model's quality, as well as SMT model's, is guaranteed by the relevance between training data and testing data. Domain adaptation (DA\nomenclature[da]{DA}{Domain Adaptation}) (e.g \cite{Rico13domain}), which is a long-time active research area in MT research, focus on improving MT system's quality to a target domain. Domain adaptation problem is then extended to multi-domain adaptation problem, whose goal is to build an ultimate MT system for many target domains. Multi-domain adaptation is however less studied than the former problem. 
\section{Motivation}

\section{Thesis contribution}

\section{Outline}