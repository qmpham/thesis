\chapter{Conclusions}
\label{chap:conclusion}
This thesis aimed to clarify the objectives of MDMT, unify the mathematical notions used in MDMT into one system of notations, and finally propose different approaches for the supervised multi-domain adaptation setting. Besides, we discussed several attempts to handle unknown test domains.

The performance of MDMT systems in individual test sets is usually considered a rule of thumb to accept or reject a novel method. Still, they are often assessed by crudely designed experiments. Moreover, the success of an MDMT system does not rely only on the in-domain performance but also on the robustness with respect to unseen domains, the cross-domain heterogeneity, the intra-domain heterogeneity, the growing number of domains, and erroneous domain tags. Our most important contribution has been to build a multi-criteria evaluation that assesses five previous properties of an MDMT system. Those five "axiomatic" properties correspond to many issues reported in the research of (multi-)domain adaptation, which, however, have never been systematically formalized and assessed with well-designed tests. We built an MDMT testbed in $English-French$ inspired by our proposed multi-criteria evaluation. The data in our testbed consists of seven domains collected from OPUS. Furthermore, this collection is highly unbalanced, which is ideal for assessing MDMT systems. We reimplemented and evaluated a large set of popular MDMT methods that have been frequently used as baselines for comparing with novel MDMT methods. We demonstrated that our MDMT testbed was challenging and revealed many weaknesses of MDMT approaches, thus ideal for assessing the future work in MDMT. Furthermore, this work illustrates the need to use a wide range of domains to evaluate MDMT systems.

Secondly, our three proposal MDMT systems, including \system{LDR}, \system{CDR} and \system{FT-Res-Gated}, constitute different ways to partition parameters/nodes between a subset of domain-agnostic ones and a subset of domain-specific ones. Those systems can close the gap with fine-tuning in a well-conditioned MDMT setting while being robust to erroneous domain tags. However, our proposed methods are still far from fulfilling all of our MDMT multi-criteria evaluations.

The domains' unbalanced train data challenges all the model-centric MDMT approaches. Effectively, the performance of an MDMT model in each domain depends largely on how often train instances of that domain are presented to that model. A heuristic fixed sampling of the train domains usually lags behind more sophisticated dynamical sampling strategies \citep{Wang20balancing}. Moreover, fixed sampling strategies can not generalize for non-standard test distributions such as uni-domain adaptation, bi-domain adaptation, or unseen domain adaptation. We studied a group of dynamical sampling strategies which are parametrizable and learned during the training. These methods can adapt the sampling strategy to any predefined test distribution. Moreover, we demonstrated that this type of sampling strategy upper-bounds fixed sampling strategies in general cases while achieving good performance in particular circumstances such as uni-domain adaptation, bi-domain adaptation, or unseen domain adaptation.

Besides, we analyzed several approaches for unknown test domains. These approaches rely on text retrieval, which searches for the most similar translations given a source sentence. There are two propositions to consume the retrieved examples: 1) fine-tuning the current NMT model with these examples; 2) Encoding retrieved examples by an additional encoder or simply concatenating to the source sentence. On the one hand, those methods strongly outperform strong MDMT baselines such as fine-tuning in many domains. On the other hand, those approaches rely on a strong similarity of the retrieved examples and admit a considerable latency due to the retrieval search and the processing of the retrieved examples or the fine-tuning step.

\section*{Perspectives}

Our work revisited the MDMT literature and illustrated several interesting problems that lack attention from the community, such as the robustness with respect to unknown test domains. For the popular supervised MDMT setting, we described five properties of an effective MDMT system. Each of these fundamental requirements opens many possibilities to improve the quality of an MDMT system. Our future work will be to improve these qualities of an MDMT system.

All model-centric approaches share the same underlying idea, which is to distinguish domain-agnostic parameters and domain-specific parameters. However, the heterogeneity in the proximity of the domains leaves an open question on whether the partition of domain-agnostic and domain-specific parameters in one MDMT model can be optimized automatically rather than predefined heuristically. Furthermore, the sampling strategies should be optimized automatically with respect to the test distribution rather than being chosen heuristically. Our study of dynamical sampling strategies is the first step in that direction. The process of searching for the best hyperparameters or the best partitions for each pair of MDMT "problem-method" should be carried by machine learning approaches such as Reinforcement Learning.

Next, personalized MT is an extreme case of MDMT \citep{Michel18extreme} which constitutes an exciting application in the MT industry. This situation rests on adapting an MT system to a large number of translators' writing styles; thus, MDMT systems are a possible solution. It would, however, requires scaling the methods developed in this thesis to thousands of domains, which remains a non-trivial task.

Besides, we have seen in Chapter~\ref{chap:priming} that retrieval-based MT demonstrated surprisingly good performance in MDMT. However, this paradigm relies on the retrieval process, which is predefined a priori and unrelated to the translation task. That leaves an open avenue for developing retrieval processes dedicated to the retrieval-based models.

Finally, we hope that future work in multi-domain machine translation will rely on our five axiomatic requirements and pay more attention to the experimental design to assess the proposed method's ability accurately. Furthermore, despite the importance of in-domain performance, the robustness against variable test distributions should be equivalently taken into account. As multilingual machine translation, multi-domain machine translation is a promising paradigm for the MT industry and still needs lots of effort to achieve its long-term objective.





























































































